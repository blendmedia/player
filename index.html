<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Blend Player</title>
  <style>
    .BlendPlayer {
      position: relative;
      /* overflow:  hidden; */
      /* contain:  strict; */
    }
    .BlendPlayer__video {
      /* position: absolute; */
    }
  </style>
</head>
<body>
  <video src="./testing-2d.mp4" id="video" autoplay preload loop></video>
  <script>
    const video = document.querySelector("#video");

    async function player(video) {

      // Load some shaders
      const vert = await (await fetch("./video.vert")).text();
      const frag = await (await fetch("./video.frag")).text();

      let videoTexture = null;
      let gl = null;


      let vw = 0, vh = 0;
      if (!video.parentNode) {
        console.error("<video> tag must be present in the DOM");
        return false;
      }
      const play = function() {
        return video.play() || Promise.resolve(true);
      }

      const closestPow2 = val => 2**Math.round(Math.log2(val));

      function initTextures() {
        videoTexture = gl.createTexture();
        gl.bindTexture(gl.TEXTURE_2D, videoTexture);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
      }

      function updateTexture() {
        if (!video.isPlaying) {
          return;
        }
        try {
          gl.bindTexture(gl.TEXTURE_2D, videoTexture);
          gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
          gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA,
                gl.UNSIGNED_BYTE, video);
        } catch (e) {
          // not ready
        }
      }

      function updateLoop() {
        gl.viewport(0, 0, canvas.width, canvas.height);
        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
        mat4.perspective(45, gl.viewportWidth / gl.viewportHeight, 0.1, 100.0, pMatrix);

        updateTexture();
        requestAnimationFrame(updateLoop);
      }

      function initWebGL(canvas) {
        gl = null;

        // Try to grab the standard context. If it fails, fallback to experimental.
        gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');

        // If we don't have a GL context, give up now
        if (!gl) {
          alert('Unable to initialize WebGL. Your browser may not support it.');
        }

        return gl;
      }

      const canvas = document.createElement("canvas");
      canvas.width = 600;
      canvas.height = 600;
      const wrapper = document.createElement("div");
      gl = initWebGL(canvas);
      // Set clear color to black, fully opaque
      gl.clearColor(0.0, 0.0, 0.0, 1.0);
      // Enable depth testing
      gl.enable(gl.DEPTH_TEST);
      // Near things obscure far things
      gl.depthFunc(gl.LEQUAL);
      // Clear the color as well as the depth buffer.
      gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
      initTextures();
      updateLoop();
      wrapper.className = "BlendPlayer";
      canvas.className = "BlendPlayer__canvas";
      video.classList.add("BlendPlayer__video");
      wrapper.appendChild(canvas);
      video.parentNode.insertBefore(wrapper, video);
      wrapper.appendChild(video);

      play().catch(e => console.warn(e));

    }

    player(video);
  </script>
</body>
</html>
